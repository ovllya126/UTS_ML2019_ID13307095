{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ovllya126/UTS_ML2019_ID13307095/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzFLYv2pZlid",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jor5PTXZs9S",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdzC0ln3ZxTC",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqmbpfwWZzo2",
        "colab_type": "text"
      },
      "source": [
        "The research proposes a new method for human face recognition called Fisherfaces, which can have high recognition rates under various light illumination and face expressions (Belhumeur, Hespanha & Kriegman 1997). The algorithm of it is based on two important feature extraction techniques used for dimensional reduction, Fisher’s Linear Discriminant Analysis (FLD or LDA) and Principal Components Analysis (PCA).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFvST5lwdE5m",
        "colab_type": "text"
      },
      "source": [
        "As the most challenged problem for face recognition is that although pictures of human face with varying lighting but fixed poses can be considered as lying in a 3-D spaces, face images in real world have deviation because of self-shadow and expressions, and consequently images cannot be observed as Lambertian surface, and the classification would be complicated. Therefore, selecting the most relevant or informative low-dimensional features of observed images is the essential point for face recognition (Wright et al. 2008).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uegAzemidGAr",
        "colab_type": "text"
      },
      "source": [
        "This method can solve the problem by projecting high dimensional spaces into a lower dimensional linear subspace in order to reduce the deviation while preserving\n",
        "discrimination. In this way, the within-class scatter can be non-singular and be reduced while maintaining the between-class scatter, and as the result, Fisherfaces can be more tolerant in lighting variation and different face expressions than other methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOi5wMtcdJyO",
        "colab_type": "text"
      },
      "source": [
        "To prove this theorem, authors mention other three popular methods, including correlation, Eigenface and Linear Subspaces, to have comparisons.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ut-KOLcdLyo",
        "colab_type": "text"
      },
      "source": [
        "Among them, correlation is a method using nearest neighbour classifier to find the most correlating point with test sets in learning sets, but it has some disadvantages containing unreliable in various lighting, huge consumed cost and storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaoInXX_dNZD",
        "colab_type": "text"
      },
      "source": [
        "While Eigenfaces can tackle above problems in correlation. It is based on PCA, and like Fisherfaces, it also project images into 1-D space, but it maximizes all scatter including within-class scatter, leading to difficulty in clustering points in varying lighting directions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xai-jOYdPCH",
        "colab_type": "text"
      },
      "source": [
        "Unlike correlation and Eigenfaces, Linear Subspaces can be more tolerant in light variation, because it creates 3-D basis vectors for linear subspaces and compares distances between images and linear subspaces to select that of the shortest distance. But it has drawbacks, same as correlation, that it requires a great number of training data and high workload of calculation leading to consumption of cost and storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSzaih-XdQwg",
        "colab_type": "text"
      },
      "source": [
        "Although the other algorithms can also implement the projection to linear subspaces, by conducting some experiments in three circumstances using two databases to compare each method, the results proved that Fisherfaces seems to have the best performance in all experiments. Meanwhile, Linear Subspaces has a closed performance in light variation, but poor in various face expression. Correlation and Eigenface have high error rate when recognizing faces, while the results of Eigenface are affected by principal components.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qLt7u-hdScW",
        "colab_type": "text"
      },
      "source": [
        "However, this paper does not explore whether Fisherfaces can have such performance in large databases or with limited light directions for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re1DMDvGdV2g",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztrEPvk2daIj",
        "colab_type": "text"
      },
      "source": [
        "In recent years, scientist have come up with many face recognition algorithms, but the problem at that time was that most of them are unreliable under extreme variation of lighting and face expressions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HthXCLfAddE_",
        "colab_type": "text"
      },
      "source": [
        "The novelty of this paper is that it contributed a new approach that tackles the problem by combining two machine learning approaches PCA and LDA for face recognition, proposed by Turk and Pentland (1991), and Cheng et al. (1991) respectively. They are important feature extraction techniques used for dimensional reduction. With PCA, principal component axes point to data variance, and therefore, by selecting the specific principal component axes, data can be projected to reduces spaces (Spulak, Otrebski & Kubinger 2015), while LDA can separate points into two classes when projecting data to lower dimensions (Vinay et al. 2015)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmAJi4_Lde4D",
        "colab_type": "text"
      },
      "source": [
        "The paper compares the difference between these two algorithms for a two-class problem where data lie in a linear space (Figure 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0K5GjAVdlI6",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/ovllya126/UTS_ML2019_ID13307095/blob/master/Screenshot%202019-08-24%2010.59.36.png?raw=true\" width=\"350\"/>\n",
        "\n",
        "\n",
        "\n",
        "Figure 1. A comparison of PCA and FLD for a two class problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeVJSYJ1fXEp",
        "colab_type": "text"
      },
      "source": [
        "As we can see from figure 1, although there are more data projected in PCA area, the two classes are mixed, while data of two-class separate obviously in FLD area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlKRDYABeQiT",
        "colab_type": "text"
      },
      "source": [
        "To take advantages of two algorithm, the method uses PCA to reduce the dimension of the feature space to N - c, and then applies the standard FLD to reduce the dimension to c - 1. Combining them, the ratio of between-class scatter and within- class scatter can be maximum, descending the error rate of recognition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izdk9u_KfeVn",
        "colab_type": "text"
      },
      "source": [
        "The new method Fisherfaces published in 1997, which is creative firstly combining these two methods together and increasing recognition rate effectively. After 1997, there appeared many papers citing this paper and evaluating each algorithm or comparing between PCA and LDA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UUIVlGNff4C",
        "colab_type": "text"
      },
      "source": [
        "In addition, conducting some comparisons with three popular recognition methods, authors proved that Fisherfaces can be more tolerant in various lighting illumination and face expression from the results of experiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10B_92R5gmwr",
        "colab_type": "text"
      },
      "source": [
        "However, there are weakness of this method that authors did not mention. One is that when using PCA to reduce dimension, the process may lead to loss of useful information in LDA. The other is that the computation of Fisherfaces can be very complicated and complex (Anggo & Arapu 2018). They are what authors should come up with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W78RznMfhJw",
        "colab_type": "text"
      },
      "source": [
        "## Technical Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ3M_WSGfoZY",
        "colab_type": "text"
      },
      "source": [
        "The technical quality of this paper is above average but with disadvantage of limited training sample and variance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQCpd-cVfqFF",
        "colab_type": "text"
      },
      "source": [
        "The comparison experiment uses two different databases, one from Harvard Robotics Laboratory where face expressions are fixed but with systematic variation in light illumination, the other at Yale which contains variation both in lighting and face expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3nSiaCkfsh_",
        "colab_type": "text"
      },
      "source": [
        "In Harvard database, the paper separates data into five subsets having images from five illumination directions. The first experiment shows results from both extrapolation and interpolation, using different training sets and test sets. However, the number of images for training is small, with about no more than 150 training images. And the light variances are also limited, the paper only tests samples from five directions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNhjYNakfwv1",
        "colab_type": "text"
      },
      "source": [
        "It may cause inaccuracy of comparison among methods, according to Spulak, Otrebski and Kubinger (2015). The experiment uses 1000 images for training, and the result in figure 2 shows that PCA significant relies on training data, so the prediction will be affected even with lack of a small amounts of datasets. In contrast, LDA smears all classes, and as the consequent, the lack of datasets has less influence on LDA performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht_XBx45fyME",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/ovllya126/UTS_ML2019_ID13307095/blob/master/Screenshot%202019-08-24%2011.46.06.png?raw=true\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5yFrrCYfz1n",
        "colab_type": "text"
      },
      "source": [
        "In Yale database, the images were managed to two different scales, the full face and close-cropped ones. It is considerable, as it can explore the effects of backgrounds and contour.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx9_O97Jgk3b",
        "colab_type": "text"
      },
      "source": [
        "Also, there are some pre-processing for the Eigenface and correlation tests such as normalization, improving the performance of these methods. It can make each method under fair situation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frv2BrZzglY3",
        "colab_type": "text"
      },
      "source": [
        "The experiment uses “leaving-one-out” strategy, which is one of cross validation methods. With n data samples, n-1 of them are used as training set, and one point are used as the validation set. Repeating all combinations in this way, the error can be averaged for all trials, to give overall effectiveness (Gupta 2017). It is an efficient approach to deal with overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HujR0WcgokF",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5DouB6KgsNO",
        "colab_type": "text"
      },
      "source": [
        "The new approach for face recognition proposed by authors can be used in a wide range of application domain, as both PCA and LDA are applied in many areas. For example, PCA has been used in handprint recognition, human-made object recognition, industrial robotics and mobile robotics, while LDA has been exploited for generic object recognition as well as mobile robotics (Martínez & Kak 2001).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO40LIMFgtvg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Therefore, Fisherfaces is suitable for face recognition application within static images. It can be extended to dynamic recognition, containing unlock methods in smart phone, surveillance systems for polices to purchasing criminals and entrance guard in smart home systems. Besides, it can be explored in robotic fields when developing robots.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux7iGcoagu-v",
        "colab_type": "text"
      },
      "source": [
        "For further observation, the research work should focus on increasing number of datasets and variance to see the difference of performances among methods. Also, other experiments can be included with variance of poses and dynamic actions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcU9H-hfgwYN",
        "colab_type": "text"
      },
      "source": [
        "Furthermore, it can have comparisons with Independent Component Analysis (ICA), which is considered as a generalization of PCA (Yang 2002). It can reduce dependencies in the input data so that the output data can be statistically independent. In addition, Kernel PCA proposed by Schöölkopf (1998) and Kernel FLD extended by Baudat and Anouar (2000), Roth and Steinhage (2000) and Mika et al. (2000) can be referenced in further research, as ‘Kernel PCA is able to extract nonlinear features and thus provided better recognition results. Kernel FLD is able to extract the most discriminant features in the feature space.’ (Yang 2002, pp.216).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCSg1XOVgx6d",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gy-ElRog0qV",
        "colab_type": "text"
      },
      "source": [
        "The presentation of this paper is high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxkyY10vg2ZO",
        "colab_type": "text"
      },
      "source": [
        "The construction of article is completed. The beginning is the introduction of the paper, following with detailed explanation of each method, experiments, results, discussion and conclusion. Each method and opinion are supported by formula and reference. Also, the results of experiment are expressed reasonable with supports of data in forms of charts and tables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOI4Lk_Jg3n6",
        "colab_type": "text"
      },
      "source": [
        "However, some details may need to be modified. The first is that the construction of Introduction should be organized as following steps: coming up with challenges, a short introduction of what authors want to propose in this paper to tackle the problems, what it contributes, what authors are going to write in the following session. Secondly, it also may mention future work of further observation in conclusion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uQeDM-ng6ps",
        "colab_type": "text"
      },
      "source": [
        "The whole expression is smooth, so it is easy to follow the mind of authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og-SwHBEg73C",
        "colab_type": "text"
      },
      "source": [
        "## Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4dxtZ7Pg_cE",
        "colab_type": "text"
      },
      "source": [
        "Anggo, M. & Arapu, L. 2018, 'Face recognition using fisherface method', *Journal of Physics: Conference Series*, vol. 1028, IOP Publishing, p. 012119.\n",
        "\n",
        "Baudat, G. & Anouar, F. 2000, 'Generalized discriminant analysis using a kernel approach', *Neural computation*, vol. 12, no. 10, pp. 2385-404.\n",
        "\n",
        "Belhumeur, P.N., Hespanha, J.P. & Kriegman, D.J. 1997, 'Eigenfaces vs. fisherfaces: Recognition using class specific linear projection', *IEEE Transactions on Pattern Analysis & Machine Intelligence*, no. 7, pp. 711-20.\n",
        "\n",
        "Cheng, L.T., Tam, W., Stevenson, S.H., Meredith, G.R., Rikken, G. & Marder, S.R. 1991, 'Experimental investigations of organic molecular nonlinear optical polarizabilities. 1. Methods and results on benzene and stilbene derivatives', *The Journal of Physical Chemistry*, vol. 95, no. 26, pp. 10631-43.\n",
        "\n",
        "Gupta (2017), *Cross-Validation in Machine Learning*, Medium, Australia viewd 27 Aug 2019, \\<https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f \\>\n",
        "\n",
        "Martínez, A.M. & Kak, A.C. 2001, 'Pca versus lda', *IEEE transactions on pattern analysis and machine intelligence*, vol. 23, no. 2, pp. 228-33.\n",
        "\n",
        "Mika, S., Rätsch, G., Weston, J., Schölkopf, B., Smola, A.J. & Müller, K.-R. 2000, 'Invariant feature extraction and classification in kernel spaces', *Advances in neural information processing systems*, pp. 526-32.\n",
        "\n",
        "Roth, V. & Steinhage, V. 2000, 'Nonlinear discriminant analysis using kernel functions',*Advances in neural information processing systems*, pp. 568-74.\n",
        "\n",
        "Schölkopf, B., Smola, A. & Müller, K.-R. 1998, 'Nonlinear component analysis as a kernel eigenvalue problem', *Neural computation*, vol. 10, no. 5, pp. 1299-319.\n",
        "\n",
        "Spulak, D., Otrebski, R. & Kubinger, W. 2015, 'Evaluation of PCA, LDA and Fisherfaces in Appearance-based Object Detection in Thermal Infra-red Images with Incomplete Data', *Procedia Engineering*, vol. 100, pp. 1167-73.\n",
        "\n",
        "Turk, M. & Pentland, A. 1991, 'Eigenfaces for recognition', *Journal of cognitive neuroscience*,vol. 3, no. 1, pp. 71-86.\n",
        "\n",
        "Vinay, A., Shekhar, V.S., Murthy, K.B. & Natarajan, S. 2015, 'Performance study of LDA and KFA for gabor based face recognition system', *Procedia Computer Science*, vol. 57, pp.960-9.\n",
        "\n",
        "Wright, J., Yang, A.Y., Ganesh, A., Sastry, S.S. & Ma, Y. 2008, 'Robust face recognition via sparse representation', *IEEE transactions on pattern analysis and machine intelligence*, vol. 31, no. 2, pp. 210-27.\n",
        "\n",
        "Yang, M.-H. 2002, 'Kernel Eigenfaces vs. Kernel Fisherfaces: Face Recognition Using Kernel Methods', *Fgr*, vol. 2, p. 215.\n",
        "\n",
        "\n"
      ]
    }
  ]
}